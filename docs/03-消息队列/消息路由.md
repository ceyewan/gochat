# 消息路由设计

## 概述

GoChat 系统的消息路由设计采用基于 Kafka 的分布式消息队列，实现高效、可靠的消息传递和路由。本文档详细描述了消息的路由策略、流程和实现。

## 路由架构

### 整体架构

```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│   Client    │    │ im-gateway  │    │  im-logic   │    │  im-task    │
│             │    │             │    │             │    │             │
│  ┌─────────┐│    │  ┌─────────┐│    │  ┌─────────┐│    │  ┌─────────┐│
│  │WebSocket││───▶│  │  HTTP   ││───▶│  │  gRPC   ││───▶│  │  gRPC   ││
│  │         ││    │  │         ││    │  │         ││    │  │         ││
│  └─────────┘│    │  └─────────┘│    │  └─────────┘│    │  └─────────┘│
│             │    │             │    │             │    │             │
│  ┌─────────┐│    │  ┌─────────┐│    │  ┌─────────┐│    │  ┌─────────┐│
│  │   API   ││    │  │  Kafka  ││    │  │  Kafka  ││    │  │  Kafka  ││
│  │         ││    │  │Producer││    │  │Consumer││    │  │Consumer││
│  └─────────┘│    │  └─────────┘│    │  └─────────┘│    │  └─────────┘│
└─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘
       │                   │                   │                   │
       │                   │                   │                   │
       └───────────────────┼───────────────────┼───────────────────┘
                           │                   │
                           └───────────────────┘
```

### Topic 设计

| Topic | 用途 | 分区数 | 副本数 | 消费者组 |
|-------|------|--------|--------|----------|
| im-upstream-topic | 上游消息 | 10 | 3 | im-logic-group |
| im-downstream-topic-{gateway_id} | 下游消息 | 3 | 2 | gateway-{id}-group |
| im-task-topic | 任务消息 | 5 | 3 | im-task-group |

## 路由策略

### 1. 单聊消息路由

#### 路由流程

```
Client A → Gateway A → Upstream Topic → Logic → Downstream Topic (Gateway B) → Gateway B → Client B
```

#### 详细步骤

1. **消息发送**
   - Client A 发送消息到 Gateway A
   - Gateway A 验证用户身份和权限
   - Gateway A 将消息发送到 Upstream Topic

2. **消息处理**
   - Logic 服务从 Upstream Topic 消费消息
   - Logic 验证消息内容和权限
   - Logic 查询目标用户 B 的网关位置

3. **消息路由**
   - Logic 发送消息到 Gateway B 的下游 Topic
   - Gateway B 消费消息并推送给 Client B

#### 代码实现

```go
// Logic 服务路由逻辑
func (s *LogicServer) routeSingleMessage(ctx context.Context, msg *Message) error {
    // 1. 查询目标用户网关
    gatewayID, err := s.getUserGateway(ctx, msg.ToUserID)
    if err != nil {
        return err
    }
    
    // 2. 构建下游消息
    downstreamMsg := &DownstreamMessage{
        MessageID:      msg.MessageID,
        FromUserID:     msg.FromUserID,
        ToUserID:       msg.ToUserID,
        ConversationID: msg.ConversationID,
        Content:        msg.Content,
        MessageType:   msg.MessageType,
        Timestamp:      msg.Timestamp,
    }
    
    // 3. 发送到下游 Topic
    topic := fmt.Sprintf("im-downstream-topic-%s", gatewayID)
    return s.kafkaProducer.SendMessage(topic, downstreamMsg)
}
```

### 2. 群聊消息路由

#### 路由策略

根据群组大小采用不同的路由策略：

- **小群** (成员数 < 100): 直接路由到各成员网关
- **大群** (成员数 >= 100): 通过 Task 服务异步扇出

#### 小群路由流程

```
Client A → Gateway A → Upstream Topic → Logic → 多个下游 Topic → 各成员 Gateway → 各成员 Client
```

#### 大群路由流程

```
Client A → Gateway A → Upstream Topic → Logic → Task Topic → Task → 批量发送到多个下游 Topic
```

#### 代码实现

```go
// Logic 服务群聊路由逻辑
func (s *LogicServer) routeGroupMessage(ctx context.Context, msg *Message) error {
    // 1. 获取群组信息
    group, err := s.repoClient.GetGroup(ctx, &pb.GetGroupRequest{
        GroupId: msg.ConversationID,
    })
    if err != nil {
        return err
    }
    
    // 2. 根据群组大小选择路由策略
    if group.CurrentMembers < 100 {
        return s.routeSmallGroupMessage(ctx, msg, group)
    } else {
        return s.routeLargeGroupMessage(ctx, msg, group)
    }
}

// 小群消息路由
func (s *LogicServer) routeSmallGroupMessage(ctx context.Context, msg *Message, group *pb.Group) error {
    // 1. 获取群组成员
    members, err := s.repoClient.GetGroupMembers(ctx, &pb.GetGroupMembersRequest{
        GroupId: msg.ConversationID,
    })
    if err != nil {
        return err
    }
    
    // 2. 批量发送到各成员网关
    for _, member := range members.Members {
        if member.UserId == msg.FromUserID {
            continue // 跳过发送者
        }
        
        gatewayID, err := s.getUserGateway(ctx, member.UserId)
        if err != nil {
            continue
        }
        
        downstreamMsg := &DownstreamMessage{
            MessageID:      msg.MessageID,
            FromUserID:     msg.FromUserID,
            ToUserID:       member.UserId,
            ConversationID: msg.ConversationID,
            Content:        msg.Content,
            MessageType:   msg.MessageType,
            Timestamp:      msg.Timestamp,
        }
        
        topic := fmt.Sprintf("im-downstream-topic-%s", gatewayID)
        s.kafkaProducer.SendMessage(topic, downstreamMsg)
    }
    
    return nil
}

// 大群消息路由
func (s *LogicServer) routeLargeGroupMessage(ctx context.Context, msg *Message, group *pb.Group) error {
    // 1. 发送到 Task Topic
    taskMsg := &TaskMessage{
        TaskType: "group_fanout",
        Payload: map[string]interface{}{
            "group_id":        msg.ConversationID,
            "message_id":      msg.MessageID,
            "from_user_id":    msg.FromUserID,
            "content":         msg.Content,
            "message_type":    msg.MessageType,
            "exclude_user_id": msg.FromUserID,
        },
        Timestamp: time.Now().Unix(),
    }
    
    return s.kafkaProducer.SendMessage("im-task-topic", taskMsg)
}
```

### 3. 离线消息路由

#### 路由流程

```
Logic → Task Topic → Task → 持久化到数据库 → 推送通知
```

#### 实现逻辑

```go
// Logic 服务离线消息处理
func (s *LogicServer) handleOfflineMessage(ctx context.Context, msg *Message) error {
    // 1. 发送持久化任务
    taskMsg := &TaskMessage{
        TaskType: "persist_message",
        Payload: map[string]interface{}{
            "message_id":      msg.MessageID,
            "conversation_id": msg.ConversationID,
            "from_user_id":    msg.FromUserID,
            "to_user_id":      msg.ToUserID,
            "content":         msg.Content,
            "message_type":    msg.MessageType,
        },
        Timestamp: time.Now().Unix(),
    }
    
    // 2. 发送离线推送任务
    pushTaskMsg := &TaskMessage{
        TaskType: "offline_push",
        Payload: map[string]interface{}{
            "user_id":     msg.ToUserID,
            "message_id":  msg.MessageID,
            "title":       "新消息",
            "content":     fmt.Sprintf("%s: %s", msg.FromUserID, msg.Content),
            "push_type":   "message",
        },
        Timestamp: time.Now().Unix(),
    }
    
    // 批量发送任务
    tasks := []*TaskMessage{taskMsg, pushTaskMsg}
    return s.kafkaProducer.SendBatchMessages("im-task-topic", tasks)
}
```

## 网关发现和管理

### 1. 网关注册

```go
// 网关注册逻辑
func (s *GatewayServer) registerGateway() error {
    // 1. 生成网关 ID
    s.gatewayID = generateGatewayID()
    
    // 2. 注册到 etcd
    key := fmt.Sprintf("/gateways/%s", s.gatewayID)
    value := map[string]interface{}{
        "id":          s.gatewayID,
        "address":     s.config.Address,
        "port":        s.config.Port,
        "status":      "active",
        "capacity":    s.config.MaxConnections,
        "current_load": len(s.clients),
        "registered_at": time.Now().Unix(),
    }
    
    // 3. 设置租约
    lease, err := s.etcdClient.Grant(context.Background(), 30)
    if err != nil {
        return err
    }
    
    // 4. 注册并保持心跳
    _, err = s.etcdClient.Put(context.Background(), key, jsonString(value), clientv3.WithLease(lease.ID))
    if err != nil {
        return err
    }
    
    // 5. 启动心跳
    go s.keepAlive(lease.ID)
    
    return nil
}
```

### 2. 用户网关映射

```go
// 用户网关映射管理
func (s *LogicServer) getUserGateway(ctx context.Context, userID string) (string, error) {
    // 1. 从缓存查询
    cacheKey := fmt.Sprintf("user_gateway:%s", userID)
    if gatewayID, err := s.redisClient.Get(ctx, cacheKey).Result(); err == nil {
        return gatewayID, nil
    }
    
    // 2. 从 etcd 查询
    key := fmt.Sprintf("/user_gateways/%s", userID)
    resp, err := s.etcdClient.Get(ctx, key)
    if err != nil {
        return "", err
    }
    
    if len(resp.Kvs) == 0 {
        return "", errors.New("user gateway not found")
    }
    
    var gatewayInfo struct {
        GatewayID string `json:"gateway_id"`
        UpdatedAt int64  `json:"updated_at"`
    }
    
    json.Unmarshal(resp.Kvs[0].Value, &gatewayInfo)
    
    // 3. 缓存到 Redis
    s.redisClient.Set(ctx, cacheKey, gatewayInfo.GatewayID, time.Minute*5)
    
    return gatewayInfo.GatewayID, nil
}

// 更新用户网关映射
func (s *GatewayServer) updateUserGateway(userID string) error {
    key := fmt.Sprintf("/user_gateways/%s", userID)
    value := map[string]interface{}{
        "user_id":     userID,
        "gateway_id":  s.gatewayID,
        "updated_at":  time.Now().Unix(),
    }
    
    // 设置租约
    lease, err := s.etcdClient.Grant(context.Background(), 30)
    if err != nil {
        return err
    }
    
    _, err = s.etcdClient.Put(context.Background(), key, jsonString(value), clientv3.WithLease(lease.ID))
    return err
}
```

## 消息负载均衡

### 1. 分区分配策略

```go
// 分区分配算法
func (s *LogicServer) getPartition(key string, numPartitions int32) int32 {
    // 1. 计算 key 的 hash
    hash := fnv.New32a()
    hash.Write([]byte(key))
    hashValue := hash.Sum32()
    
    // 2. 取模得到分区号
    return int32(hashValue) % numPartitions
}

// 上游消息分区选择
func (s *LogicServer) getUpstreamPartition(msg *Message) int32 {
    // 按 from_user_id 分区，保证同一用户的消息顺序
    return s.getPartition(msg.FromUserID, s.config.UpstreamPartitions)
}

// 下游消息分区选择
func (s *LogicServer) getDownstreamPartition(msg *Message) int32 {
    // 按 to_user_id 分区，保证目标用户的消息顺序
    return s.getPartition(msg.ToUserID, s.config.DownstreamPartitions)
}
```

### 2. 网关负载均衡

```go
// 网关负载均衡算法
func (s *LogicServer) selectGateway(userID string) (string, error) {
    // 1. 获取所有活跃网关
    gateways, err := s.getActiveGateways()
    if err != nil {
        return "", err
    }
    
    // 2. 过滤可用网关
    availableGateways := make([]*GatewayInfo, 0)
    for _, gateway := range gateways {
        if gateway.Status == "active" && gateway.CurrentLoad < gateway.Capacity {
            availableGateways = append(availableGateways, gateway)
        }
    }
    
    if len(availableGateways) == 0 {
        return "", errors.New("no available gateway")
    }
    
    // 3. 选择负载最小的网关
    selectedGateway := availableGateways[0]
    for _, gateway := range availableGateways {
        if gateway.CurrentLoad < selectedGateway.CurrentLoad {
            selectedGateway = gateway
        }
    }
    
    return selectedGateway.ID, nil
}
```

## 消息重试和故障处理

### 1. 生产者重试

```go
// 带重试的消息发送
func (p *KafkaProducer) SendMessageWithRetry(topic string, message interface{}, maxRetries int) error {
    var lastErr error
    
    for i := 0; i < maxRetries; i++ {
        err := p.SendMessage(topic, message)
        if err == nil {
            return nil
        }
        
        lastErr = err
        time.Sleep(time.Duration(i+1) * time.Second)
    }
    
    return fmt.Errorf("failed to send message after %d retries: %v", maxRetries, lastErr)
}
```

### 2. 消费者重试

```go
// 消费者消息处理
func (c *KafkaConsumer) processMessage(msg *kafka.Message) error {
    // 1. 解析消息
    var message Message
    if err := json.Unmarshal(msg.Value, &message); err != nil {
        return err
    }
    
    // 2. 处理消息
    err := c.handler.Process(&message)
    if err != nil {
        // 3. 失败重试
        return c.handleFailedMessage(msg, err)
    }
    
    // 4. 提交 offset
    c.commitOffset(msg)
    return nil
}

// 处理失败消息
func (c *KafkaConsumer) handleFailedMessage(msg *kafka.Message, err error) error {
    // 1. 检查重试次数
    retryCount := c.getRetryCount(msg)
    if retryCount >= c.config.MaxRetries {
        // 2. 发送到死信队列
        return c.sendToDeadLetterQueue(msg, err)
    }
    
    // 3. 增加重试次数
    c.incrementRetryCount(msg)
    
    // 4. 重新发送到队列
    return c.requeueMessage(msg)
}
```

### 3. 网关故障处理

```go
// 网关故障检测
func (s *LogicServer) checkGatewayHealth(gatewayID string) error {
    // 1. 检查网关连接状态
    key := fmt.Sprintf("/gateways/%s", gatewayID)
    resp, err := s.etcdClient.Get(context.Background(), key)
    if err != nil {
        return err
    }
    
    if len(resp.Kvs) == 0 {
        return errors.New("gateway not found")
    }
    
    // 2. 检查租约是否过期
    if resp.Kvs[0].Lease == 0 {
        return errors.New("gateway lease expired")
    }
    
    // 3. 检查网关健康状态
    var gatewayInfo GatewayInfo
    json.Unmarshal(resp.Kvs[0].Value, &gatewayInfo)
    
    if gatewayInfo.Status != "active" {
        return errors.New("gateway not active")
    }
    
    return nil
}

// 网关故障转移
func (s *LogicServer) handleGatewayFailure(gatewayID string) {
    // 1. 获取故障网关的用户列表
    users, err := s.getGatewayUsers(gatewayID)
    if err != nil {
        log.Printf("Failed to get gateway users: %v", err)
        return
    }
    
    // 2. 重新分配用户到其他网关
    for _, userID := range users {
        newGatewayID, err := s.selectGateway(userID)
        if err != nil {
            log.Printf("Failed to assign new gateway for user %s: %v", userID, err)
            continue
        }
        
        // 3. 更新用户网关映射
        s.updateUserGateway(userID, newGatewayID)
        
        // 4. 通知用户重新连接
        s.notifyUserReconnect(userID, newGatewayID)
    }
}
```

## 性能优化

### 1. 批量处理

```go
// 批量消息发送
func (p *KafkaProducer) SendBatchMessages(topic string, messages []interface{}) error {
    // 1. 创建批量消息
    kafkaMessages := make([]*kafka.Message, len(messages))
    for i, msg := range messages {
        data, err := json.Marshal(msg)
        if err != nil {
            return err
        }
        
        kafkaMessages[i] = &kafka.Message{
            TopicPartition: kafka.TopicPartition{
                Topic:     &topic,
                Partition: kafka.PartitionAny,
            },
            Value: data,
        }
    }
    
    // 2. 批量发送
    return p.producer.Produce(kafkaMessages, nil)
}
```

### 2. 连接池管理

```go
// Kafka 连接池
type KafkaConnectionPool struct {
    producers map[string]*kafka.Producer
    consumers map[string]*kafka.Consumer
    mutex      sync.RWMutex
}

func (p *KafkaConnectionPool) GetProducer(brokers string) (*kafka.Producer, error) {
    p.mutex.RLock()
    if producer, exists := p.producers[brokers]; exists {
        p.mutex.RUnlock()
        return producer, nil
    }
    p.mutex.RUnlock()
    
    p.mutex.Lock()
    defer p.mutex.Unlock()
    
    // 双重检查
    if producer, exists := p.producers[brokers]; exists {
        return producer, nil
    }
    
    // 创建新的 producer
    producer, err := kafka.NewProducer(&kafka.ConfigMap{
        "bootstrap.servers": brokers,
        "client.id":         fmt.Sprintf("producer-%d", time.Now().Unix()),
    })
    
    if err != nil {
        return nil, err
    }
    
    p.producers[brokers] = producer
    return producer, nil
}
```

### 3. 缓存优化

```go
// 多级缓存
type MultiLevelCache struct {
    l1Cache *redis.Client // 本地缓存
    l2Cache *redis.Client // 分布式缓存
}

func (c *MultiLevelCache) Get(ctx context.Context, key string) (interface{}, error) {
    // 1. 先查 L1 缓存
    if val, err := c.l1Cache.Get(ctx, key).Result(); err == nil {
        return val, nil
    }
    
    // 2. 再查 L2 缓存
    if val, err := c.l2Cache.Get(ctx, key).Result(); err == nil {
        // 回填 L1 缓存
        c.l1Cache.Set(ctx, key, val, time.Minute*5)
        return val, nil
    }
    
    return nil, errors.New("key not found")
}

func (c *MultiLevelCache) Set(ctx context.Context, key string, value interface{}, expiration time.Duration) error {
    // 1. 设置 L1 缓存
    if err := c.l1Cache.Set(ctx, key, value, time.Minute*5); err != nil {
        return err
    }
    
    // 2. 设置 L2 缓存
    return c.l2Cache.Set(ctx, key, value, expiration)
}
```

## 监控和告警

### 1. 关键指标监控

```go
// 消息路由监控
type RouterMetrics struct {
    // 消息处理指标
    MessagesProcessed     prometheus.Counter
    MessagesFailed        prometheus.Counter
    MessageLatency        prometheus.Histogram
    
    // 网关指标
    GatewayConnections    prometheus.Gauge
    GatewayLoad           prometheus.Gauge
    
    // Topic 指标
    TopicLag             prometheus.Gauge
    TopicThroughput      prometheus.Counter
}

// 初始化监控指标
func NewRouterMetrics() *RouterMetrics {
    return &RouterMetrics{
        MessagesProcessed: prometheus.NewCounter(prometheus.CounterOpts{
            Name: "router_messages_processed_total",
            Help: "Total number of messages processed",
        }),
        MessagesFailed: prometheus.NewCounter(prometheus.CounterOpts{
            Name: "router_messages_failed_total",
            Help: "Total number of messages failed to process",
        }),
        MessageLatency: prometheus.NewHistogram(prometheus.HistogramOpts{
            Name:    "router_message_latency_seconds",
            Help:    "Message processing latency",
            Buckets: prometheus.DefBuckets,
        }),
        GatewayConnections: prometheus.NewGauge(prometheus.GaugeOpts{
            Name: "router_gateway_connections",
            Help: "Number of active gateway connections",
        }),
        GatewayLoad: prometheus.NewGauge(prometheus.GaugeOpts{
            Name: "router_gateway_load",
            Help: "Current load on gateways",
        }),
        TopicLag: prometheus.NewGaugeVec(prometheus.GaugeOpts{
            Name: "router_topic_lag",
            Help: "Kafka topic lag",
        }, []string{"topic"}),
        TopicThroughput: prometheus.NewCounterVec(prometheus.CounterOpts{
            Name: "router_topic_throughput_total",
            Help: "Kafka topic throughput",
        }, []string{"topic"}),
    }
}
```

### 2. 告警规则

```go
// 告警检查
func (s *LogicServer) checkAlerts() {
    // 1. 检查 Topic Lag
    s.checkTopicLagAlert()
    
    // 2. 检查网关负载
    s.checkGatewayLoadAlert()
    
    // 3. 检查消息延迟
    s.checkMessageLatencyAlert()
    
    // 4. 检查错误率
    s.checkErrorRateAlert()
}

// 检查 Topic Lag 告警
func (s *LogicServer) checkTopicLagAlert() {
    topics := []string{"im-upstream-topic", "im-task-topic"}
    
    for _, topic := range topics {
        lag, err := s.getTopicLag(topic)
        if err != nil {
            log.Printf("Failed to get topic lag: %v", err)
            continue
        }
        
        if lag > 1000 {
            s.sendAlert("high_topic_lag", map[string]interface{}{
                "topic": topic,
                "lag":   lag,
                "level": "warning",
            })
        }
    }
}
```

## 总结

GoChat 系统的消息路由设计采用了基于 Kafka 的分布式架构，通过合理的 Topic 设计、路由策略和负载均衡机制，实现了高效、可靠的消息传递。系统支持单聊、群聊、离线消息等多种场景，并提供了完善的故障处理、性能优化和监控告警机制。